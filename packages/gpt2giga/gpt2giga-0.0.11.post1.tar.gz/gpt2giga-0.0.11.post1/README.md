# Утилита для проксирования OpenAI-запросов в GigaChat

Утилита gpt2giga — это прокси-сервер, который перенаправляет запросы, отправленные в OpenAI API, в GigaChat API.

При старте утилиты запускается HTTP-сервер, адрес которого нужно использовать вместо адреса OpenAI API, заданного в вашем приложении (например, `https://api.openai.com/v1/`).
Утилита обработает запрос и перенаправит его заданной [модели GigaChat](https://developers.sber.ru/docs/ru/gigachat/models).
После получения ответа модели, она передаст его в приложение в формате OpenAI.

Утилита работает как с запросами на генерацию, так и с запросами на создание эмбеддингов (эндпоинты `/embeddings` или `/v1/embeddings`).

Общая схема работы gpt2giga:

```mermaid
sequenceDiagram
    participant YourApp as Приложение
    participant gpt2giga
    participant GigaChat as GigaChat API

    YourApp->>gpt2giga: OpenAI-запрос
    gpt2giga->>GigaChat: Запрос формата GigaChat API
    GigaChat->>gpt2giga: Ответ формата GigaChat API
    gpt2giga->>YourApp: OpenAI-ответ
```

## Возможности gpt2giga

С помощью gpt2giga вы можете:

- использовать возможности моделей OpenAI и полностью заменить ChatGPT на GigaChat;
- вызывать функции через API, включая передачу и выполнение функций с аргументами;
- обрабатывать ответ модели в режиме потоковой генерации токенов с помощью параметра `stream=true`;
- перенаправлять запросы на создание эмбеддингов (поддерживаются эндпоинты `/embeddings` и `/v1/embeddings`);
- работать в асинхронном режиме с множеством потоков запросов от нескольких клиентов;
- отображать подробные сведения о запросах и ответах при включенном verbose-режиме логирования;
- задавать параметры работы как с помощью аргументов командной строки, так и с помощью переменных окружения (`.env`).

## Начало работы

### Запуск в Docker

1. Отредактируйте `docker-compose.yml`, чтобы указать ваш API-ключ. Пример для `docker-compose.yml`:
   ```yaml
   environment:
      - GIGACHAT_CREDENTIALS: <your_api_key>
   ```
2. Запустите контейнер с помощью Docker Compose: `docker-compose up -d`

### Запуск на локальной машине

Для начала работы:

1. Установите пакет gpt2giga с помощью менеджера пакетов pip:
   
   ```sh
   pip install gpt2giga
   ```
   
   Вы также можете использовать исходники:
   
   ```sh
   pip install git+https://github.com/ai-forever/gpt2giga.git
   ```

   После установки пакета вы сможете использовать команду `gpt2giga`, которая позволяет запускать и настраивать прокси-сервер.

2. Переименуйте файл [`.env.example`](./.env.example) в `.env` и сохраните его в корне своего проекта:

   ```sh
   cp .env.example .env
   ```

3. В файле `.env` укажите данные для авторизации в GigaChat API.

   GigaChat API поддерживает различные способы авторизации, которые отличаются в зависимости от типа вашей учетной записи.

   > [!NOTE]
   > Кроме переменных gpt2giga в `.env` можно указать переменные окружения, которые поддерживает [python-библиотека GigaChat](https://github.com/ai-forever/gigachat#настройка-переменных-окружения).


4. В терминале выполните команду `gpt2giga`.

Запустится прокси-сервер, по умолчанию доступный по адресу `localhost:8090`.
Адрес и порт сервера, а также другие параметры, можно настроить с помощью аргументов командной строки или переменных окружения.

## Изменение параметров gpt2giga

Вы можете изменять параметры работы утилиты с помощью аргументов командной строки или переменных окружения.

### Аргументы командной строки

Утилита поддерживает аргументы:

- `--host <HOST>` — хост, на котором запускается прокси-сервер. По умолчанию `localhost`;
- `--port <PORT>` — порт, на котором запускается прокси-сервер. По умолчанию `8090`;
- `--verbose` — включить подробный вывод логов (запросы и ответы);
- `--pass-model` — передавать в GigaChat API модель, которую указал клиент в поле `model` в режиме чата;
- `--pass-token` — передавать токен, полученный в заголовке `Authorization`, в GigaChat API. С помощью него можно настраивать передачу ключей в GigaChat через `OPENAI_API_KEY`;
- `--base-url <BASE_URL>` — базовый URL для GigaChat API. По умолчанию берется значение переменной `GIGACHAT_BASE_URL` или поля `BASE_URL` внутри пакета;
- `--model <MODEL>` — модель для запросов в GigaChat. По умолчанию `GIGACHAT_MODEL`;
- `--timeout <TIMEOUT>` — таймаут для запросов к GigaChat API. По умолчанию `600` секунд;
- `--embeddings <EMBED_MODEL>` — модель, которая будет использоваться для создания эмбеддингов. По умолчанию `EmbeddingsGigaR`;
- `--env-path <PATH>` — путь до файла с переменными окружения `.env`. По умолчанию ищется `.env` в текущей директории.
- `--verify-ssl-certs <True/False>` - проверять сертификаты SSL (по умолчанию `True`)
- `--enable-images` — экспериментальный флаг, который включает передачу изображений в формате OpenAI в GigaChat API

### Переменные окружения

Для настройки параметров утилиты также можно использовать переменные окружения, заданные в файле `.env`.

Список доступных переменных:

- `PROXY_HOST="localhost"` — хост, на котором запускается прокси-сервер. По умолчанию `localhost`;
- `PROXY_PORT="8090"` — порт, на котором запускается прокси-сервер. По умолчанию `8090`;
- `GPT2GIGA_VERBOSE="False"` — включает/отключает вывод подробной информации;
- `GPT2GIGA_PASS_MODEL="False"` — передавать ли модель, указанную в запросе, непосредственно в GigaChat;
- `GPT2GIGA_PASS_TOKEN="False"` — передавать токен, полученный в заголовке `Authorization`, в GigaChat API;
- `GIGACHAT_BASE_URL="https://gigachat.devices.sberbank.ru/api/v1"` — базовый URL GigaChat;
- `GIGACHAT_MODEL="GigaChat"` — модель GigaChat API, которая будет обрабатывать запросы по умолчанию;
- `GPT2GIGA_TIMEOUT="600"` — таймаут для запросов к GigaChat API (в секундах);
- `GPT2GIGA_EMBEDDINGS="EmbeddingsGigaR"` — модель для создания эмбеддингов.

Также можно использовать переменные, которые поддерживает [библиотека GigaChat](https://github.com/ai-forever/gigachat#%D0%BD%D0%B0%D1%81%D1%82%D1%80%D0%BE%D0%B9%D0%BA%D0%B0-%D0%BF%D0%B5%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D1%8B%D1%85-%D0%BE%D0%BA%D1%80%D1%83%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F):

- `GIGACHAT_USER` и `GIGACHAT_PASSWORD` — для авторизации с помощью с помощью логина и пароля.
- `GIGACHAT_CREDENTIALS` — для авторизации с помощью ключа авторизации.
- `GIGACHAT_ACCESS_TOKEN` — для авторизации с помощью токен доступа, полученного в обмен на ключ.
- `GIGACHAT_VERIFY_SSL_CERTS` — для того, что бы проверять SSL сертификаты, по умолчанию `False`.

### Пример запуска утилиты с заданными параметрами

Для запуска прокси-сервера с заданным адресом и портом выполните команду:

```sh
gpt2giga \
    --host 127.0.0.1 \
    --port 8080 \
    --verbose \
    --pass-model \
    --pass-token \
    --base-url https://gigachat.devices.sberbank.ru/api/v1 \
    --model GigaChat-Max \
    --timeout 300 \
    --embeddings EmbeddingsGigaR
```

После запуска сервер будет перенаправлять все запросы, адресованные OpenAI API, в GigaChat API.

## Авторизация с помощью заголовка

Утилита может пробовать принимать содержимое заголовка `Authorization` и авторизироваться через него в GigaChat API (через креды, юзер-парль или access_token)

Для этого нужно запустить gpt2giga с аргументом `--pass-token` или использовать переменную окружения `GPT2GIGA_PASS_TOKEN=True`. 

Поддерживаются варианты:

- `giga-cred-<credentials>:<scope>` — для авторизации credentials + scope
- `giga-user-<user>:<password>` — для авторизации через юзер:пароль
- `giga-auth-<access_token>` — для передачи access_token (который получается одним из первых двух способов)

## Совместимые приложения

Таблица содержит приложения, проверенные на совместную работу с gpt2giga.

| Приложение                              | Описание                                                                                                                                           |
| --------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Aider](https://aider.chat/)            | AI-ассистент для написания приложений.<br /> Подробнее о запуске и настройке Aider для работы с gpt2giga — в [README](/integrations/aider)         |
| [n8n](https://n8n.io/)                  | Платформа для создания nocode-агентов                                                                                                              |
| [Cline](https://github.com/cline/cline) | AI-ассистент разработчика                                                                                                                          |

## Лицензия

Проект распространяется под лицензией MIT.
Подробная информация — в файле [LICENSE](LICENSE).
