{"id": "2978d47d-bd47-41d1-8d9e-e77e35fc0153", "display_name": "zsxkib/jina-clip-v2", "description": null, "short_desc": null, "endpoints": [{"id": "predict_predictions_post", "display_name": "predict_predictions_post", "description": "Run a single prediction on the model", "short_desc": "Predict", "path": "/predictions", "parameters": [{"name": "prefer", "type": "string", "required": false, "default": null, "location": "header", "param_schema": {"type": "string", "title": "Prefer"}, "description": null}, {"name": "text", "type": "string", "required": false, "default": null, "location": "body", "param_schema": {"type": "string", "title": "Text", "x-order": 0, "description": "Text content to embed (up to 8192 tokens). If both text and image provided, text embedding will be first in returned list."}, "description": "Text content to embed (up to 8192 tokens). If both text and image provided, text embedding will be first in returned list."}, {"name": "image", "type": ["file", "string"], "required": false, "default": null, "location": "body", "param_schema": {"type": "string", "title": "Image", "format": "uri", "x-order": 1, "description": "Image file to embed (optimal size: 512x512). If both text and image provided, image embedding will be second in returned list."}, "description": "Image file to embed (optimal size: 512x512). If both text and image provided, image embedding will be second in returned list."}, {"name": "embedding_dim", "type": "integer", "required": false, "default": 64, "location": "body", "param_schema": {"type": "integer", "title": "Embedding Dim", "default": 64, "maximum": 1024, "minimum": 64, "x-order": 2, "description": "Matryoshka dimension - output embedding dimension (64-1024)"}, "description": "Matryoshka dimension - output embedding dimension (64-1024)"}, {"name": "output_format", "type": "string", "required": false, "default": "base64", "location": "body", "param_schema": {"allOf": [{"$ref": "#/components/schemas/output_format"}], "default": "base64", "x-order": 3, "description": "Format to use in outputs"}, "description": "Format to use in outputs"}], "responses": {"200": {"content": {"application/json": {"schema": {"$ref": "#/components/schemas/PredictionResponse"}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"$ref": "#/components/schemas/HTTPValidationError"}}}, "description": "Validation Error"}}, "timeout_s": null}], "specification": "socaity", "used_models": [], "category": ["b3a961b9-9466-47e6-90df-92ba01f0bd31"], "family_id": "07c392c4-ae7d-4551-9233-d129250bcb4f", "service_address": {"url": "https://api.socaity.ai/v1/zsxkib/jina-clip-v2"}, "created_at": "2025-06-18T13:00:02.865916+00:00", "version": "e42c901d817b500d511ab13343c0e125e55a7a37"}