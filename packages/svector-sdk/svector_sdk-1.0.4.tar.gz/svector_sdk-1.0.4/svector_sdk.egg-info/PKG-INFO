Metadata-Version: 2.4
Name: svector-sdk
Version: 1.0.4
Summary: Official Python SDK for SVECTOR AI Models - Advanced conversational AI and language models
Home-page: https://github.com/svector-corporation/svector-python
Author: SVECTOR Team
Author-email: SVECTOR Team <support@svector.co.in>
Maintainer-email: SVECTOR Team <support@svector.co.in>
License: MIT
Project-URL: Homepage, https://www.svector.co.in
Project-URL: Documentation, https://www.svector.co.in/docs
Project-URL: Repository, https://github.com/svector-corporation/svector-python
Project-URL: Bug Tracker, https://github.com/svector-corporation/svector-python/issues
Project-URL: Changelog, https://github.com/svector-corporation/svector-python/blob/main/CHANGELOG.md
Keywords: svector,ai,machine-learning,api,llm,chatbot,artificial-intelligence,conversational-ai,language-models
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Internet :: WWW/HTTP :: Dynamic Content
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: requests>=2.25.0
Requires-Dist: typing-extensions>=4.0.0; python_version < "3.10"
Provides-Extra: dev
Requires-Dist: pytest>=6.0; extra == "dev"
Requires-Dist: pytest-cov>=2.10; extra == "dev"
Requires-Dist: black>=21.0; extra == "dev"
Requires-Dist: flake8>=3.8; extra == "dev"
Requires-Dist: mypy>=0.900; extra == "dev"
Requires-Dist: twine>=3.0; extra == "dev"
Requires-Dist: build>=0.7; extra == "dev"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# SVECTOR Python SDK

[![PyPI version](https://badge.fury.io/py/svector.svg)](https://badge.fury.io/py/svector)
[![Python Support](https://img.shields.io/pypi/pyversions/svector.svg)](https://pypi.org/project/svector/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

The official Python SDK for **SVECTOR AI Models**. Build powerful AI applications with advanced conversational AI and language models.

## üöÄ Installation

```bash
pip install svector
```

## üéØ Quick Start

### Basic Usage

```python
from svector import SVECTOR

# Initialize the client
client = SVECTOR(api_key="your-api-key-here")

# Simple chat completion
response = client.chat.create(
    model="spec-3-turbo:latest",
    messages=[
        {"role": "user", "content": "What is artificial intelligence?"}
    ]
)

print(response["choices"][0]["message"]["content"])
```

### Streaming Responses

```python
# Stream responses in real-time
stream = client.chat.create(
    model="spec-3-turbo:latest",
    messages=[
        {"role": "user", "content": "Write a poem about technology"}
    ],
    stream=True
)

for event in stream:
    if event.get("choices") and event["choices"][0].get("delta", {}).get("content"):
        print(event["choices"][0]["delta"]["content"], end="", flush=True)
```

### File Upload and RAG

```python
# Upload a file for RAG
file_response = client.files.create("document.pdf", purpose="rag")
file_id = file_response["file_id"]

# Ask questions about the uploaded file
response = client.chat.create(
    model="spec-3-turbo:latest",
    messages=[
        {"role": "user", "content": "Summarize this document"}
    ],
    files=[{"type": "file", "id": file_id}]
)

print(response["choices"][0]["message"]["content"])
```

## üñ•Ô∏è Command Line Interface

SVECTOR also provides a powerful CLI:

```bash
# Set up your API key
svector config set-key your-api-key-here

# Start chatting
svector chat "Hello, SVECTOR!"

# Stream responses
svector stream "Write a poem about AI"

# List available models
svector models

# Upload files for RAG
svector file upload document.pdf

# Ask questions about files
svector ask "Summarize this document" --file file-123
```

## üìö API Reference

### SVECTOR Client

```python
client = SVECTOR(
    api_key="your-api-key",           # Required: Your SVECTOR API key
    base_url="https://spec-chat.tech",  # Optional: Custom API base URL
    timeout=30,                       # Optional: Request timeout in seconds
    max_retries=3                     # Optional: Max retry attempts
)
```

### Chat Completions

```python
response = client.chat.create(
    model="spec-3-turbo:latest",      # Required: Model name
    messages=[                        # Required: List of messages
        {"role": "user", "content": "Hello"}
    ],
    temperature=0.7,                  # Optional: 0.0 to 2.0
    max_tokens=150,                   # Optional: Max tokens to generate
    files=[                           # Optional: Files for RAG
        {"type": "file", "id": "file-123"}
    ],
    stream=False                      # Optional: Enable streaming
)
```

### Models API

```python
# List available models
models = client.models.list()
print(models["models"])
```

### Files API

```python
# Upload from file path
response = client.files.create("path/to/file.pdf", purpose="rag")

# Upload from bytes
with open("file.pdf", "rb") as f:
    response = client.files.create(f.read(), purpose="rag", filename="file.pdf")

# Upload from file object
with open("file.pdf", "rb") as f:
    response = client.files.create(f, purpose="rag", filename="file.pdf")
```

## üîß Advanced Examples

### Multi-turn Conversation

```python
conversation = [
    {"role": "system", "content": "You are a helpful programming assistant."},
    {"role": "user", "content": "How do I create a function in Python?"},
]

response = client.chat.create(
    model="spec-3-turbo:latest",
    messages=conversation,
    temperature=0.3
)

# Add the AI response to conversation history
conversation.append({
    "role": "assistant", 
    "content": response["choices"][0]["message"]["content"]
})

# Continue the conversation
conversation.append({
    "role": "user", 
    "content": "Can you show me an example?"
})

response = client.chat.create(
    model="spec-3-turbo:latest",
    messages=conversation
)
```

### Multi-file RAG

```python
# Upload multiple files
file1 = client.files.create("technical_specs.pdf")
file2 = client.files.create("user_manual.pdf")

# Query across multiple documents
response = client.chat.create(
    model="spec-3-turbo:latest",
    messages=[
        {"role": "user", "content": "Compare the technical specifications with the user manual"}
    ],
    files=[
        {"type": "file", "id": file1["file_id"]},
        {"type": "file", "id": file2["file_id"]}
    ]
)
```

### Error Handling

```python
from svector import SVECTOR, AuthenticationError, RateLimitError, APIError

try:
    client = SVECTOR(api_key="invalid-key")
    response = client.chat.create(
        model="spec-3-turbo:latest",
        messages=[{"role": "user", "content": "Hello"}]
    )
except AuthenticationError:
    print("Invalid API key")
except RateLimitError:
    print("Rate limit exceeded")
except APIError as e:
    print(f"API error: {e}")
```

## üåü Features

- **‚úÖ Complete API Coverage**: Chat completions, streaming, file upload, RAG
- **‚úÖ Type Safety**: Full type hints for better development experience
- **‚úÖ Error Handling**: Comprehensive error types and retry logic
- **‚úÖ Streaming Support**: Real-time response streaming
- **‚úÖ File Upload**: Support for various file formats and RAG
- **‚úÖ CLI Interface**: Command-line tool for quick interactions
- **‚úÖ Production Ready**: Robust error handling and retry mechanisms

## üîë Authentication

Get your API key from the [SVECTOR Dashboard](https://www.svector.co.in/dashboard).

Set it as an environment variable:

```bash
export SVECTOR_API_KEY="your-api-key-here"
```

Or pass it directly to the client:

```python
client = SVECTOR(api_key="your-api-key-here")
```

## üåç Supported Models

- `spec-3-turbo:latest` - General purpose model with excellent performance
- `spec-3-pro:latest` - Advanced reasoning model for complex tasks

Get the latest list:

```python
models = client.models.list()
```

## üìã Requirements

- Python 3.8+
- `requests` library (automatically installed)

## ü§ù Support

- **Documentation**: [https://www.svector.co.in/docs](https://www.svector.co.in/docs)
- **Email**: support@svector.co.in
- **Issues**: [GitHub Issues](https://github.com/svector-corporation/svector-python/issues)

## üìÑ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## üöÄ Getting Started

1. **Install the package**:
   ```bash
   pip install svector
   ```

2. **Get your API key**: Visit [https://www.svector.co.in](https://www.svector.co.in)

3. **Start building**:
   ```python
   from svector import SVECTOR
   
   client = SVECTOR(api_key="your-key")
   response = client.chat.create(
       model="spec-3-turbo:latest",
       messages=[{"role": "user", "content": "Hello, SVECTOR!"}]
   )
   ```

---

**Built with ‚ù§Ô∏è by the SVECTOR Team**
