{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import omnipose\n",
    "\n",
    "# set up plotting defaults\n",
    "from omnipose.plot import imshow\n",
    "omnipose.plot.setup()\n",
    "\n",
    "# This checks to see if you have set up your GPU properly.\n",
    "# CPU performance is a lot slower, but not a problem if you \n",
    "# are only processing a few images.\n",
    "from omnipose.gpu import use_gpu\n",
    "# use_GPU = use_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = list(sorted(glob(\"frames/*.png\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose_omni import io, transforms\n",
    "from omnipose.utils import normalize99\n",
    "imgs = [io.imread(f) for f in files]\n",
    "\n",
    "# fig = plt.figure(figsize=[40]*2,frameon=False) # initialize figure\n",
    "\n",
    "for k in range(len(imgs)):\n",
    "    img = transforms.move_min_dim(imgs[k]) # move the channel dimension last\n",
    "    if len(img.shape)>2:\n",
    "        imgs[k] = np.mean(img,axis=-1) # or just turn into grayscale \n",
    "      \n",
    "\n",
    "    imgs[k] = normalize99(imgs[k])\n",
    "\n",
    "imgs = np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cellpose_omni\n",
    "from cellpose_omni import models\n",
    "from cellpose_omni.models import MODEL_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bact_phase_omni'\n",
    "model = models.CellposeModel(gpu=False, model_type=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "chans = [0,0] #this means segment based on first channel, no second channel \n",
    "\n",
    "\n",
    "# define parameters\n",
    "params = {\n",
    "    'channels':chans, # always define this with the model\n",
    "    'rescale': None, # upscale or downscale your images, None = no rescaling \n",
    "    'mask_threshold': 3, # erode or dilate masks with higher or lower values between -5 and 5 \n",
    "    'flow_threshold': 0, # default is .4, but only needed if there are spurious masks to clean up; slows down output\n",
    "    'transparency': True, # transparency in flow output\n",
    "    'omni': True, # we can turn off Omnipose mask reconstruction, not advised \n",
    "    'cluster': True, # use DBSCAN clustering\n",
    "    'resample': True, # whether or not to run dynamics on rescaled grid or original grid \n",
    "    'verbose': False, # turn on if you want to see more output \n",
    "    'tile': False, # average the outputs from flipped (augmented) images; slower, usually not needed \n",
    "    'niter': None, # default None lets Omnipose calculate # of Euler iterations (usually <20) but you can tune it for over/under segmentation \n",
    "    'augment': False, # Can optionally rotate the image and average network outputs, usually not needed \n",
    "    # 'affinity_seg': True, # new feature, stay tuned...\n",
    "}\n",
    "\n",
    "tic = time.time() \n",
    "masks, flows, styles = model.eval(imgs,**params)\n",
    "\n",
    "net_time = time.time() - tic\n",
    "print('total segmentation time: {}s'.format(net_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "for filename, mask in zip(files, masks):\n",
    "    number = str(Path(filename).stem).split(\".png\")[0]\n",
    "    cv.imwrite(f\"frames/{number}-mask.png\", mask)\n",
    "    np.savetxt(f\"frames/{number}-markers.csv\", mask, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
