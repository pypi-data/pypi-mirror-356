from pathlib import Path
from typing import Optional
from os.path import commonpath
from datetime import datetime, timezone
import tiktoken
from dataclasses import dataclass


@dataclass
class FileStats:
    """Statistics for a single file."""

    chars: int
    tokens: int


@dataclass
class FormattedFile:
    """A formatted file with its stats."""

    path: Path
    content: str
    stats: FileStats
    formatted_content: str


@dataclass
class FormatResult:
    """Result of formatting one or more files."""

    files: list[FormattedFile]
    root_path: Path
    timestamp: datetime
    formatted_content: str
    total_chars: int = 0
    total_tokens: int = 0
    has_header: bool = True

    def __str__(self) -> str:
        """Return the formatted content."""
        return self.formatted_content


def format_file(
    file_path: Path, root_path: Path, content: Optional[str] = None
) -> FormattedFile:
    """Format a single file as XML-style markdown and return structured result."""
    try:
        # Use provided content or read from file
        if content is None:
            content = file_path.read_text()

        # Calculate stats
        stats = FileStats(chars=len(content), tokens=estimate_tokens(content))

        # Use string paths for comparison to handle symlinks and different path formats
        file_str = str(file_path.resolve())
        root_str = str(root_path.resolve())

        # Remove the root path and any leading slashes
        if file_str.startswith(root_str):
            rel_path = file_str[len(root_str) :].lstrip("/\\")
        else:
            rel_path = file_str  # Fallback to full path if not a subpath

        language = guess_language(file_path)

        # Build the XML tag with attributes
        tag_attrs = [f'path="{rel_path}"']
        if language:
            tag_attrs.append(f'language="{language}"')

        attrs_str = " ".join(tag_attrs)

        formatted_content = f"""<file {attrs_str}>
{content}
</file>"""

        return FormattedFile(
            path=file_path,
            content=content,
            stats=stats,
            formatted_content=formatted_content,
        )

    except Exception as e:
        # Return empty stats for failed files
        return FormattedFile(
            path=file_path,
            content=f"<!-- Error processing {file_path}: {str(e)} -->",
            stats=FileStats(chars=0, tokens=0),
            formatted_content=f"<!-- Error processing {file_path}: {str(e)} -->",
        )


def create_header(result: FormatResult) -> str:
    """Create a header with metadata about the export."""
    timestamp = result.timestamp.strftime("%Y-%m-%d %H:%M:%S UTC")

    # Create a table-like format for files
    rel_paths = []
    for f in result.files:
        try:
            rel_path = str(f.path.relative_to(result.root_path))
            # Make sure path is not empty or just "."
            if not rel_path or rel_path == ".":
                # For GitHub items, use a more descriptive name
                if (
                    isinstance(f.path, Path)
                    and f.path.name
                    and (
                        "_pr_" in f.path.name
                        or "_issue_" in f.path.name
                        or "_discussion_" in f.path.name
                    )
                ) or (
                    # Also check for GitHub blob files (they have repo_ref_filepath pattern)
                    isinstance(f.path, Path)
                    and f.path.name
                    and "_" in f.path.name
                    and len(f.path.name.split("_"))
                    >= 3  # repo_ref_filepath has at least 3 parts
                ):
                    # This appears to be a GitHub item, use a more descriptive name
                    rel_path = f.path.name
                else:
                    rel_path = f.path.name or str(f.path)
        except ValueError:
            rel_path = str(f.path)  # Fallback to full path if not a subpath
        rel_paths.append(rel_path)

    # Use the minimum of the longest path or 50 chars
    max_path_len = (
        max(len(path) for path in rel_paths) if rel_paths else 4
    )  # Min "Path" header width
    max_path_len = max(max_path_len, 4)  # Ensure min width for "Path" header
    max_path_len = min(max_path_len, 50)  # Cap path length for readability

    # Calculate line counts
    file_lines = {f.path: f.content.count("\n") + 1 for f in result.files}
    total_lines = sum(file_lines.values())

    header = [
        "<!--",
        f"Generated by copychat on {timestamp}",
        f"Root path: {result.root_path}",
        f"Summary: {len(result.files)} files, ~{result.total_tokens:,} tokens, {total_lines:,} lines",
        "",
        "Files:",
        "┌" + "─" * (max_path_len + 2) + "┬" + "─" * 12 + "┬" + "─" * 10 + "┐",
        f"│ {'Path':<{max_path_len}} │ {'Tokens':>10} │ {'Lines':>8} │",
        "├" + "─" * (max_path_len + 2) + "┼" + "─" * 12 + "┼" + "─" * 10 + "┤",
    ]

    # Format each file as a table row
    for f in sorted(result.files, key=lambda x: str(x.path)):
        # Calculate relative path for this specific file
        try:
            rel_path = str(f.path.relative_to(result.root_path))
            # Make sure path is not empty or just "."
            if not rel_path or rel_path == ".":
                # For GitHub items, use a more descriptive name
                if (
                    isinstance(f.path, Path)
                    and f.path.name
                    and (
                        "_pr_" in f.path.name
                        or "_issue_" in f.path.name
                        or "_discussion_" in f.path.name
                    )
                ) or (
                    # Also check for GitHub blob files (they have repo_ref_filepath pattern)
                    isinstance(f.path, Path)
                    and f.path.name
                    and "_" in f.path.name
                    and len(f.path.name.split("_"))
                    >= 3  # repo_ref_filepath has at least 3 parts
                ):
                    # This appears to be a GitHub item, use a more descriptive name
                    rel_path = f.path.name
                else:
                    rel_path = f.path.name or str(f.path)
        except ValueError:
            rel_path = str(f.path)  # Fallback to full path if not a subpath
        
        if len(rel_path) > max_path_len:
            trunc_len = max_path_len - 3
            rel_path = "..." + rel_path[-trunc_len:]

        lines = file_lines[f.path]
        header.append(
            f"│ {rel_path:<{max_path_len}} │ {f.stats.tokens:>10,} │ {lines:>8,} │"
        )

    header.extend(
        [
            "└" + "─" * (max_path_len + 2) + "┴" + "─" * 12 + "┴" + "─" * 10 + "┘",
            "-->",
            "",
        ]
    )

    return "\n".join(header)


def create_display_header(result: FormatResult) -> str:
    """Create a display-friendly header without XML comments."""
    timestamp = result.timestamp.strftime("%Y-%m-%d %H:%M:%S UTC")

    # Create a table-like format for files
    rel_paths = []
    for f in result.files:
        try:
            rel_path = str(f.path.relative_to(result.root_path))
            # Make sure path is not empty or just "."
            if not rel_path or rel_path == ".":
                # For GitHub items, use a more descriptive name
                if (
                    isinstance(f.path, Path)
                    and f.path.name
                    and (
                        "_pr_" in f.path.name
                        or "_issue_" in f.path.name
                        or "_discussion_" in f.path.name
                    )
                ) or (
                    # Also check for GitHub blob files (they have repo_ref_filepath pattern)
                    isinstance(f.path, Path)
                    and f.path.name
                    and "_" in f.path.name
                    and len(f.path.name.split("_"))
                    >= 3  # repo_ref_filepath has at least 3 parts
                ):
                    # This appears to be a GitHub item, use a more descriptive name
                    rel_path = f.path.name
                else:
                    rel_path = f.path.name or str(f.path)
        except ValueError:
            rel_path = str(f.path)  # Fallback to full path if not a subpath
        rel_paths.append(rel_path)

    # Use the minimum of the longest path or 50 chars
    max_path_len = (
        max(len(path) for path in rel_paths) if rel_paths else 4
    )  # Min "Path" header width
    max_path_len = max(max_path_len, 4)  # Ensure min width for "Path" header
    max_path_len = min(max_path_len, 50)  # Cap path length for readability

    # Calculate line counts
    file_lines = {f.path: f.content.count("\n") + 1 for f in result.files}
    total_lines = sum(file_lines.values())

    header = [
        f"Generated by copychat on {timestamp}",
        f"Root path: {result.root_path}",
        f"Summary: {len(result.files)} files, ~{result.total_tokens:,} tokens, {total_lines:,} lines",
        "",
        "┌" + "─" * (max_path_len + 2) + "┬" + "─" * 12 + "┬" + "─" * 10 + "┐",
        f"│ {'Path':<{max_path_len}} │ {'Tokens':>10} │ {'Lines':>8} │",
        "├" + "─" * (max_path_len + 2) + "┼" + "─" * 12 + "┼" + "─" * 10 + "┤",
    ]

    # Format each file as a table row
    for f in sorted(result.files, key=lambda x: str(x.path)):
        # Calculate relative path for this specific file
        try:
            rel_path = str(f.path.relative_to(result.root_path))
            # Make sure path is not empty or just "."
            if not rel_path or rel_path == ".":
                # For GitHub items, use a more descriptive name
                if (
                    isinstance(f.path, Path)
                    and f.path.name
                    and (
                        "_pr_" in f.path.name
                        or "_issue_" in f.path.name
                        or "_discussion_" in f.path.name
                    )
                ) or (
                    # Also check for GitHub blob files (they have repo_ref_filepath pattern)
                    isinstance(f.path, Path)
                    and f.path.name
                    and "_" in f.path.name
                    and len(f.path.name.split("_"))
                    >= 3  # repo_ref_filepath has at least 3 parts
                ):
                    # This appears to be a GitHub item, use a more descriptive name
                    rel_path = f.path.name
                else:
                    rel_path = f.path.name or str(f.path)
        except ValueError:
            rel_path = str(f.path)  # Fallback to full path if not a subpath
        
        if len(rel_path) > max_path_len:
            trunc_len = max_path_len - 3
            rel_path = "..." + rel_path[-trunc_len:]

        lines = file_lines[f.path]
        header.append(
            f"│ {rel_path:<{max_path_len}} │ {f.stats.tokens:>10,} │ {lines:>8,} │"
        )

    header.append(
        "└" + "─" * (max_path_len + 2) + "┴" + "─" * 12 + "┴" + "─" * 10 + "┘"
    )

    return "\n".join(header)


def format_files(files: list[tuple[Path, str]]) -> FormatResult:
    """Format files into markdown with XML-style tags.

    Args:
        files: List of (path, content) tuples to format

    Returns:
        FormatResult containing all formatting information
    """
    if not files:
        return FormatResult(
            files=[],
            root_path=Path("."),
            timestamp=datetime.now(timezone.utc),
            formatted_content="<!-- No files found matching criteria -->\n",
            has_header=False,
        )

    # Find common root path using os.path.commonpath
    paths = [f[0] for f in files]
    str_paths = [str(f.absolute()) for f in paths]
    root_path = Path(commonpath(str_paths))

    # Format each file
    formatted_files = []
    total_chars = 0
    total_tokens = 0

    for file_path, content in files:
        formatted = format_file(file_path, root_path, content)
        formatted_files.append(formatted)
        total_chars += formatted.stats.chars
        total_tokens += formatted.stats.tokens

    result = FormatResult(
        files=formatted_files,
        root_path=root_path,
        timestamp=datetime.now(timezone.utc),
        total_chars=total_chars,
        total_tokens=total_tokens,
        formatted_content="",  # Will be set after header
    )

    # Create header and combine all parts
    header = create_header(result)
    formatted_content = "\n".join(
        [header] + [f.formatted_content for f in formatted_files]
    )

    # Update the formatted content
    result.formatted_content = formatted_content

    return result


# Keep existing helper functions unchanged
def estimate_tokens(text: str) -> int:
    """Estimate the number of tokens in the text using GPT tokenizer."""
    try:
        # Using cl100k_base (used by GPT-4, Claude)
        encoding = tiktoken.get_encoding("cl100k_base")
        return len(encoding.encode(text))
    except Exception:
        # Fallback to rough estimate if tiktoken fails
        return len(text) // 4  # Rough estimate: ~4 chars per token


def guess_language(file_path: Path) -> Optional[str]:
    """Guess the programming language based on file extension."""
    ext = file_path.suffix.lower()

    # Common language mappings
    language_map = {
        ".py": "python",
        ".js": "javascript",
        ".ts": "typescript",
        ".jsx": "jsx",
        ".tsx": "tsx",
        ".html": "html",
        ".css": "css",
        ".scss": "scss",
        ".rs": "rust",
        ".go": "go",
        ".java": "java",
        ".cpp": "cpp",
        ".c": "c",
        ".h": "c",
        ".hpp": "cpp",
        ".rb": "ruby",
        ".php": "php",
        ".sh": "bash",
        ".yaml": "yaml",
        ".yml": "yaml",
        ".json": "json",
        ".md": "markdown",
        ".sql": "sql",
        ".r": "r",
        ".swift": "swift",
        ".kt": "kotlin",
        ".kts": "kotlin",
        ".scala": "scala",
        ".pl": "perl",
        ".pm": "perl",
    }

    return language_map.get(ext)
