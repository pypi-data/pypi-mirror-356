"""Functions to read, update, and write SPSS data."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% auto 0
__all__ = ['Metadata', 'reformat_metadata', 'read_sav', 'pack_variable_types', 'write_sav']

# %% ../nbs/00_core.ipynb 3
from dataclasses import dataclass
import pandas as pd
from pathlib import Path
import pyreadstat
from typing import Optional, Any, Literal
import warnings

from fastcore.utils import *
from fastcore.test import *

# %% ../nbs/00_core.ipynb 5
@dataclass
class Metadata:
    variable_basename: str
    label: str
    field_values: dict[int, str]
    field_type: Literal["Numeric", "String", "Date", "Time"] #TODO: expand to include possible other types
    field_width: int
    decimals: int
    variable_type: Literal["nominal", "scale", "ordinal"]

# %% ../nbs/00_core.ipynb 9
def reformat_metadata(m: pyreadstat.metadata_container) -> dict[dict[str, Any]]:
    "Reformat metadata into a more readable and consistent format."
    field_type, decimals = _unpack_variable_types(m.original_variable_types)
    metadata = {
        "Label": m.column_names_to_labels,
        "Field Type": field_type,
        "Field Width": m.variable_display_width,
        "Decimals": decimals,
        "Variable Type": m.variable_measure,
        "Field Values": m.variable_value_labels
    }
    return metadata

def _unpack_variable_types(variable_types: dict) -> tuple[dict[str, str], dict[str, int]]:
    """
    Separate the `variable_types` dictionary from pyreadstat's metadata container 
    into field type and decimal places.
    """
    field_type = {}
    decimals = {}
    
    for key, value in variable_types.items():
        if value.startswith('F'):
            field_type[key] = 'Numeric'
            dec = value.split('.')[1]
            decimals[key] = int(dec) if dec != '0' else 0
        elif value.startswith('A'):
            field_type[key] = 'String'
            decimals[key] = 0
        elif value.startswith(('EDATE', 'DATE')):
            field_type[key] = 'Date'
            decimals[key] = 0
        elif value.startswith('TIME'):
            field_type[key] = 'Time'
            decimals[key] = 0
        else:
            warnings.warn(f"Unknown field type discovered for {key}: {value}.")
    
    return field_type, decimals

# %% ../nbs/00_core.ipynb 12
def read_sav(
    file_path: str | Path, 
    usecols: Optional[list[str]] = None,
    ) -> pd.DataFrame:
    "Wrapper around `pyreadstat.read_sav()` to reformat metadata."
    df, meta = pyreadstat.read_sav(Path(file_path), usecols=usecols)
    meta = reformat_metadata(meta)
    return df, meta

# %% ../nbs/00_core.ipynb 14
def pack_variable_types(m: dict[str, dict[str, Any]], # metadata in nested dictionary format
                        ) -> dict[str, str]:
    """
    Convert metadata parameters related to variable format 
    into an appropriate schema for pyreadstat.
    """
    field_type = m["Field Type"]
    field_width = m["Field Width"]
    decimals = m["Decimals"]
    
    combined_types = _combine_dicts(field_type, field_width, decimals)

    return _pack_variable_types(combined_types)

def _combine_dicts(ft: dict[str, str], 
                   fw: dict[str, int], 
                   d: dict[str, int],
                   warn: bool = True
                   ) -> dict[str, tuple[Any, Any, Any]]:
    """
    Combine three dictionaries into one, with shared keys and tuple values, 
    and raise warnings for non-shared keys.
    """
    # Find the intersection of keys
    shared_keys = set(ft.keys()) & set(fw.keys()) & set(d.keys())
    
    # Find keys that are not shared across all dictionaries
    all_keys = set(ft.keys()) | set(fw.keys()) | set(d.keys())
    non_shared_keys = all_keys - shared_keys
    
    # Raise warnings for non-shared keys
    if non_shared_keys and warn:
        warnings.warn(f"Keys not shared across all dictionaries: {non_shared_keys}")
    
    # Map for field types
    field_type = {
        "Numeric": "F",
        "String": "A",
        "Date": "DATE",
        "Time": "TIME"
    }

    # Construct the output dictionary
    combined_dict = {key: (field_type.get(ft[key]), fw[key], d[key]) for key in shared_keys}
    
    return combined_dict
    
def _pack_variable_types(data: dict[str, tuple[str, int, int]]
                         ) -> dict[str, str]:
    """Private function to perform the logic for `pack_variable_types`."""
    d = {}
    
    for var, values in data.items():
        f_type, f_width, dec = values
        
        if f_type == "F" and dec > 0:
            d[var] = f"{f_type}{f_width}.{dec}"
        else:
            d[var] = f"{f_type}{f_width}"

    return d

# %% ../nbs/00_core.ipynb 16
# TODO: could be actual Data and Metadata class/types
def write_sav(
    dst_path: str | Path, # path to save output file
    df: pd.DataFrame, # raw data
    metadata: dict[str, dict[str, Any]] # corresponding metadata
    ) -> None:
    """Save dataset to SPSS using `pyreadstat` library."""
    with open(dst_path, 'w'):
        # If no exception raised, file is not being used, and can be written
        pass

    pyreadstat.write_sav(
        df, 
        dst_path,
        column_labels=metadata["Label"],
        variable_value_labels=metadata["Field Values"],
        variable_display_width=metadata["Field Width"],
        variable_measure=metadata["Variable Type"],
        variable_format=pack_variable_types(metadata),
        row_compress=True
    )
