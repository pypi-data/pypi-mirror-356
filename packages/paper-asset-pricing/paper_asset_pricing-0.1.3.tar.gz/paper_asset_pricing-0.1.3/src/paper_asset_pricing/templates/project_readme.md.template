# {{project_name}}

A P.A.P.E.R (Platform for Asset-Pricing Experimentation and Research) project.

Initialized on: {{creation_date}}
P.A.P.E.R Tools Version: {{paper_asset_pricing_version}}

## Project Structure

This project follows the standard P.A.P.E.R directory structure:

- `{{CONFIGS_DIR_NAME}}/`: Contains all configuration files for the project.
    - `{{DEFAULT_PROJECT_CONFIG_NAME}}`: Main project configuration linking all components.
    - `{{DATA_COMPONENT_CONFIG_FILENAME}}`: Defines the data ingestion and wrangling pipeline.
    - `{{MODELS_COMPONENT_CONFIG_FILENAME}}`: Defines the models to be trained and evaluated.
    - `{{PORTFOLIO_COMPONENT_CONFIG_FILENAME}}`: Defines portfolio construction and backtesting strategies.
- `{{DATA_DIR_NAME}}/`: Contains all data-related assets.
    - `raw/`: Place your raw, original data files here (e.g., CSVs).
    - `processed/`: The destination for cleaned, analysis-ready datasets generated by the `paper-data` pipeline.
    - `scripts/`: Place custom Python transformation scripts here. These scripts can be called from your `data-config.yaml` to perform complex, project-specific data manipulations.
- `{{MODELS_DIR_NAME}}/`: Contains all modeling-related outputs.
    - `predictions/`: Stores the out-of-sample predictions generated by each model.
    - `evaluations/`: Contains performance metrics (e.g., RÂ², MSE) for each model.
    - `saved/`: Stores saved model objects for each training window.
- `{{PORTFOLIOS_DIR_NAME}}/`: Contains all portfolio analysis outputs.
    - `results/`: Stores performance reports, charts, and monthly returns for each backtested strategy.
    - `additional_datasets/`: Place for supplementary files needed for portfolio analysis (e.g., risk-free rates, benchmarks).
- `{{LOG_FILE_NAME}}`: A central log file that captures detailed output from all pipeline phases.
- `.gitignore`: A pre-configured file to prevent temporary files and processed data from being committed to version control.
- `README.md`: This file.

## How to Use

1.  **Configure**: Edit the YAML files in the `configs/` directory to define your research pipeline.
2.  **Add Data**: Place any local raw data files in `data/raw/` and custom transformation scripts in `data/scripts/`.
3.  **Execute**: Run the pipeline phases sequentially from your terminal:
    ```bash
    paper execute data
    paper execute models
    paper execute portfolio
    ```
