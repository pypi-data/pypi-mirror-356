---
description: Smolagents best practices: Guidelines for building efficient and reliable agents using smolagents.
globs:
alwaysApply: false
---
# Smolagents Best Practices & Coding Guidelines

## Introduction

This guide outlines best practices and coding considerations for building effective, robust, and maintainable agents with `smolagents`. Adhering to these principles will help in creating simpler, more reliable, and efficient agentic systems. The core philosophy is to simplify agent workflows and minimize reliance on non-deterministic LLM calls where possible.

## Core Principle: Simplify Your Workflow

The most fundamental guideline for building good `smolagents` is to **simplify the agent's workflow as much as possible**. Complex workflows increase the chances of errors, latency, and cost.

## Key Guidelines & Coding Considerations

To achieve workflow simplification, consider the following:

### 1. Reduce the Number of LLM Calls

Minimize interactions with the Large Language Model (LLM). Each call introduces potential for error and adds to latency and cost.

- **Strive for fewer, more impactful LLM interactions.**
- **Bad Practice**: Relying on the LLM for simple data transformations or sequential queries that can be batched.
- **Good Practice**: Design prompts and tool interactions to extract maximum information in a single LLM call where appropriate.

### 2. Group Tools Logically

Whenever an agent needs to perform multiple related actions (e.g., calling several APIs to gather information for a single conceptual task), consolidate these into a single, unified tool.

- **Conceptual Example (from documentation)**: Instead of separate tools for `get_travel_distance` and `get_weather_forecast`, create one tool `get_spot_information`.

- **Pseudo-code Implementation Sketch**:
  ```python
  # Bad: Two separate tools requiring two LLM decisions/calls
  # class GetTravelDistanceTool(BaseTool):
  #     def call(self, spot_name: str) -> float: ...
  #
  # class GetWeatherForecastTool(BaseTool):
  #     def call(self, spot_name: str) -> str: ...

  # Good: One unified tool (example assuming a BaseTool structure)
  class GetSpotInformationTool: # Replace with actual smolagents BaseTool if applicable
      name = "get_spot_information"
      description = "Provides travel distance and weather forecast for a surf spot."

      # Synchronous execution (if smolagents tools are sync by default)
      def run(self, spot_name: str) -> dict:
          # Internal implementation calls actual APIs
          distance = self._fetch_distance(spot_name)
          weather = self._fetch_weather(spot_name)
          return {"spot": spot_name, "distance_km": distance, "weather": weather}

      # Asynchronous execution (if smolagents supports/prefers async tools)
      async def arun(self, spot_name: str) -> dict:
          distance = await self._afetch_distance(spot_name)
          weather = await self._afetch_weather(spot_name)
          return {"spot": spot_name, "distance_km": distance, "weather": weather}

      # Helper methods (not part of tool interface for LLM)
      def _fetch_distance(self, spot_name: str) -> float:
          # ... implementation ...
          return 0.0 # Placeholder
      async def _afetch_distance(self, spot_name: str) -> float:
          # ... async implementation ...
          return 0.0 # Placeholder
      def _fetch_weather(self, spot_name: str) -> str:
          # ... implementation ...
          return "Sunny" # Placeholder
      async def _afetch_weather(self, spot_name: str) -> str:
          # ... async implementation ...
          return "Sunny" # Placeholder
  ```
- **Benefit**: This reduces the number of LLM calls, simplifies the agent's decision-making process, and lowers the risk of errors.

### 3. Prefer Deterministic Logic over Agentic Decisions

Where possible, implement logic using deterministic functions (i.e., standard Python code) rather than relying on the LLM to make decisions or perform computations that can be handled programmatically.

- **Use agentic (LLM-driven) decisions only when necessary** for tasks that genuinely require LLM reasoning (e.g., understanding nuanced natural language, complex planning based on ambiguous information, creative generation).

- **Pseudo-code Example**:
  ```python
  # Scenario: Determine if a user query is a greeting.
  user_query = "Hello there, how are you?"

  # Bad: Using LLM for a simple classification that can be programmed.
  # This is slow, expensive, and less reliable for simple tasks.
  #
  #   agent_prompt = f"Is the following user query a greeting? Answer '''yes''' or '''no'''. Query: {user_query}"
  #   llm_response = llm.invoke(agent_prompt) # Fictional LLM call
  #   is_greeting_llm = llm_response.content.lower() == '''yes'''


  # Good: Using deterministic Python code for straightforward tasks.
  # This is fast, cheap, reliable, and easy to test.
  def is_greeting_deterministic(query: str) -> bool:
      greetings = ["hello", "hi", "hey", "good morning", "good afternoon", "greetings"]
      query_lower = query.lower()
      return any(greeting in query_lower for greeting in greetings)

  is_greeting_code = is_greeting_deterministic(user_query)
  # print(f"Deterministic check: Is greeting? {is_greeting_code}")
  ```
- **Benefit**: Deterministic code is more reliable, predictable, faster, cheaper, and easier to test and debug than LLM-driven logic for suitable tasks.

### 4. Implement Robust Error Handling and Retries

While simplification reduces errors, agentic systems interact with external services (LLMs, APIs) that can fail.
The `Smolagents` documentation mentions: "Well-programmed agentic systems have good error logging and retry mechanisms anyway, so the LLM engine has a chance to self-correct their mistake."

- **Coding Consideration**:
  - Wrap external calls (to LLMs, or tools that call external APIs) in try-except blocks.
  - Implement retry logic (e.g., using libraries like `tenacity` for exponential backoff) for transient errors.
  - Log errors effectively for monitoring and debugging.
  - Consider mechanisms for the agent to report failure gracefully or ask for clarification if retries are exhausted.
  ```python
  # Example structure for a tool method with retries (conceptual)
  # import time
  # from tenacity import retry, stop_after_attempt, wait_exponential # Example library
  #
  # class RobustWebServiceTool: # Assuming a BaseTool or similar structure
  #     name = "query_robust_service"
  #     description = "Queries an external web service with retry logic."
  #
  #     @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
  #     def _call_external_api(self, params: dict) -> dict:
  #         # print(f"Attempting to call external API with {params}...")
  #         # response = actual_external_api.call(params) # Replace with real API call
  #         # if not response.ok: # Fictional response object check
  #         #     raise Exception(f"API Error: {response.status_code} - {response.text}")
  #         # return response.json()
  #         # Placeholder for demonstration:
  #         if random.random() < 0.5: # Simulate transient failure
  #             print("Simulating API failure...")
  #             raise ConnectionError("Simulated transient API error")
  #         print("Simulating API success!")
  #         return {"data": "success", "params": params}
  #
  #     def run(self, query: str) -> dict: # Or arun for async
  #         try:
  #             params = {"q": query}
  #             result = self._call_external_api(params)
  #             return {"status": "success", "data": result}
  #         except Exception as e:
  #             # Log error (e.g., import logging; logging.error(f"Service call failed: {e}"))
  #             print(f"Error querying service after retries: {e}")
  #             return {"status": "error", "message": str(e), "details": "Failed to query service after multiple attempts."}
  #
  # Note: This example uses 'tenacity' for retries. Adapt to smolagents' specific
  # error handling patterns or other retry libraries as appropriate.
  # Ensure your tool's run/arun methods handle exceptions gracefully.
  ```

## Rationale for these Practices

Following these guidelines leads to:

- **Reduced Costs**: Fewer LLM calls and more efficient deterministic logic mean lower operational expenses.
- **Lower Latency**: Simpler workflows, fewer LLM interactions, and fast deterministic code result in quicker responses.
- **Decreased Error Risk**: Reducing complexity, minimizing LLM decision points, and robust error handling contribute to more reliable agents.
- **Improved Maintainability & Testability**: Deterministic components are easier to test and maintain. Clear tool definitions improve overall system understanding.
