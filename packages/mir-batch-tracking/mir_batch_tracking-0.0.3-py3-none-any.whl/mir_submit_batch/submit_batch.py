"""CLI uploader â€“ users run:  python -m cli_tool.cli_tool ..."""
import argparse, hashlib, os, json, requests, sys, mimetypes
from datetime import datetime, timezone

# -------- helpers ---------

def warn_if_large(path: str, limit_mb: int = 200):
    size_mb = os.path.getsize(path) / 1_048_576
    if size_mb > limit_mb:
        print(f"âš ï¸  File is {size_mb:.1f} MB (> {limit_mb} MB). It may be split server-side.")
    else:
        print(f"ğŸ“„ File size: {size_mb:.1f} MB (limit: {limit_mb} MB)")

def validate_input_format(lines: list, endpoint: str = None):
    """Check if input is in proper batch request format or API request format"""
    if not lines:
        print("âŒ Empty input file")
        return False
        
    # Handle both string lines and pre-parsed objects
    if isinstance(lines[0], str):
        first_line = json.loads(lines[0])
    else:
        first_line = lines[0]
    
    # Check if it's batch request format (preferred - contains endpoint in URL)
    if all(key in first_line for key in ["custom_id", "method", "url", "body"]):
        detected_url = first_line.get("url", "")
        print(f"âœ… Detected batch request format ({len(lines)} requests)")
        print(f"ğŸ¯ Endpoint detected from URL field: {detected_url}")
        
        if endpoint and detected_url != endpoint:
            print(f"âš ï¸  Note: Batch URL '{detected_url}' differs from manual endpoint '{endpoint}'")
            print("   The batch URL will take precedence")
        return True
    
    # For non-batch format, validate based on endpoint or use auto-detection
    if endpoint:
        # Manual endpoint specified - validate format
        if endpoint == "/v1/chat/completions":
            if any(key in first_line for key in ["model", "messages"]):
                print(f"âœ… Detected chat completion format ({len(lines)} requests)")
                print("ğŸ’¡ Server will convert to batch request format automatically")
                return True
        elif endpoint == "/v1/completions":
            if any(key in first_line for key in ["model", "prompt"]):
                print(f"âœ… Detected text completion format ({len(lines)} requests)")
                print("ğŸ’¡ Server will convert to batch request format automatically")
                return True
        elif endpoint == "/v1/embeddings":
            if any(key in first_line for key in ["model", "input"]):
                print(f"âœ… Detected embedding format ({len(lines)} requests)")
                print("ğŸ’¡ Server will convert to batch request format automatically")
                return True
        elif endpoint == "/v1/responses":
            if any(key in first_line for key in ["model", "input"]) and "input" in first_line:
                print(f"âœ… Detected response format ({len(lines)} requests)")
                print("ğŸ’¡ Server will convert to batch request format automatically")
                return True
        
        print(f"âŒ Invalid format for endpoint {endpoint}. Expected either:")
        print("   1. Batch request format: {\"custom_id\": \"...\", \"method\": \"POST\", \"url\": \"...\", \"body\": {...}}")
        print(f"   2. Direct API format for {endpoint}")
        return False
    else:
        # Auto-detection mode (recommended)
        if any(key in first_line for key in ["model", "messages", "prompt", "input"]):
            print(f"âœ… Detected API request format ({len(lines)} requests)")
            print("ğŸ¯ Server will auto-detect endpoint from request structure")
            
            # Give a hint about what was detected
            if "messages" in first_line:
                print("   Likely: Chat Completions API")
            elif "input" in first_line and isinstance(first_line.get("input"), list):
                # Check if it looks like responses API
                input_data = first_line["input"]
                if any(isinstance(item, dict) and "role" in item for item in input_data):
                    print("   Likely: Responses API")
                else:
                    print("   Likely: Embeddings API")
            elif "prompt" in first_line:
                print("   Likely: Text Completions API")
            elif "input" in first_line:
                print("   Likely: Embeddings API")
                
            return True
        else:
            print("âŒ Invalid format. Expected either:")
            print("   1. Batch request format: {\"custom_id\": \"...\", \"method\": \"POST\", \"url\": \"...\", \"body\": {...}}")
            print("   2. API request format with fields like 'model', 'messages', 'prompt', or 'input'")
            return False

# -------- main ---------

def main():
    ap = argparse.ArgumentParser(description="Submit OpenAI batch job to central server")
    
    # Check for list-endpoints first to avoid requiring other arguments
    if "--list-endpoints" in sys.argv:
        print("ğŸ“‹ Supported OpenAI Batch Endpoints:")
        print("  /v1/chat/completions: Chat completions (text generation with conversation context)")
        print("  /v1/embeddings: Text embeddings (vector representations of text)")
        print("  /v1/completions: Text completions (simple text generation)")
        print("  /v1/responses: AI assistant responses (beta feature)")
        print("\nğŸ¯ Detection Rules:")
        print("  â€¢ Batch format: URL field is used directly (most reliable)")
        print("  â€¢ Non-batch format: Auto-detected from request structure")
        print("    - messages field â†’ /v1/chat/completions")
        print("    - input field with roles â†’ /v1/responses")
        print("    - input field without roles â†’ /v1/embeddings")
        print("    - prompt field â†’ /v1/completions")
        print("\nğŸ’¡ Recommendation: Use batch format with explicit URL field for best reliability")
        return
    
    ap.add_argument("--project-id", required=True, help="Your OpenAI project ID (e.g., proj_xxxxxxxxx)")
    ap.add_argument("--input", required=True, help="JSONL file to send")
    ap.add_argument("--server", required=True, help="Server root URL, e.g. http://165.132.142.28:9551")
    ap.add_argument("--tag", default="", help="Optional label visible in dashboard")
    ap.add_argument("--endpoint", default=None, 
                   choices=["/v1/chat/completions", "/v1/completions", "/v1/embeddings", "/v1/responses"],
                   help="(Optional) OpenAI API endpoint (default: auto-detect from URL field in batch format or request structure)")
    ap.add_argument("--list-endpoints", action="store_true", help="List supported endpoints and exit")
    args = ap.parse_args()

    if not os.path.isfile(args.input):
        sys.exit("â›” input file not found")

    warn_if_large(args.input)

    # Validate project ID format
    if not args.project_id.startswith("proj_"):
        print("âš ï¸  Warning: Project ID should start with 'proj_'")

    # Read messages but keep file raw too (server may streamâ€‘upload)
    with open(args.input, "r", encoding="utf8") as f:
        lines = f.readlines()
    messages = [json.loads(l) for l in lines]

    if not validate_input_format(messages, args.endpoint):
        sys.exit("âŒ Invalid input format")

    payload = {
        "project_id": args.project_id,
        "messages": messages,
        "tag": args.tag,
        "submitted_at": datetime.now(timezone.utc).isoformat(),
    }
    
    # Only include endpoint if manually specified
    if args.endpoint:
        payload["endpoint"] = args.endpoint

    r = requests.post(f"{args.server}/submit_batch", json=payload, timeout=300)
    r.raise_for_status()
    result = r.json()
    print("âœ… submitted!", json.dumps(result, indent=2))
    
    # Show helpful info
    if "project_name" in result:
        print(f"\nğŸ“‹ Project: {result['project_name']}")
    print(f"ğŸ†” Job ID: {result['job_group_id']}")
    
    endpoint_info = result.get('endpoint', args.endpoint or 'unknown')
    auto_detected = result.get('endpoint_auto_detected', False)
    if auto_detected:
        print(f"ğŸ¯ Endpoint: {endpoint_info} (auto-detected)")
    else:
        print(f"ğŸ¯ Endpoint: {endpoint_info} (manually specified)")
    
    WEBUI_URL = 'https://mir-lab425b.tailbc97a0.ts.net/batch_tracking'
    print(f"ğŸŒ Track progress at: {WEBUI_URL}")
    print(f"ğŸ”‘ Login with Project ID: {args.project_id}")

if __name__ == "__main__":
    main()