# AIOpStack

[![Python â‰¥3.8](https://img.shields.io/badge/python-3.8%2B-brightgreen.svg)](https://www.python.org/)
[![LangChain v0.3.25](https://img.shields.io/badge/LangChain-0.3.25-blue.svg)](https://pypi.org/project/langchain/)
[![LangGraph v0.4.8](https://img.shields.io/badge/LangGraph-0.4.8-orange.svg)](https://pypi.org/project/langgraph/)
[![LangChainÂ MCPÂ Adapters v0.1.7](https://img.shields.io/badge/LangChain--MCP--Adapters-0.1.7-purple.svg)](https://pypi.org/project/langchain-mcp-adapters/)

---

AIOpStack is a collection of AI Operational Agents built with Langchain/LangGraph and Streamlitâ€‘based GUI for operational interaction and visualization.

ğŸŒ [English](README.md) | [ç®€ä½“ä¸­æ–‡](README.zh.md)

### ğŸ¯ Motivation

1. **Fastâ€‘boot** â€“ DevOps and sysadmins often test multiple MCPs for automation, but setup can be timeâ€‘consuming. AIOpStack drastically reduces study and setup time.  
2. **Lightweight** â€“ IDEs like Cursor and VSCode with Cline are powerful but resourceâ€‘heavy. AIOpStack stays minimal and nimble.  
3. **Local Deployments** â€“ Deploy locally to access private environments.  
4. **Free & Open** â€“ Fully openâ€‘source, no vendor lockâ€‘in or licensing fees.

### ğŸš€ Features

- **OpenAIâ€‘compatible LLM API integration** â€“ Connect to any OpenAIâ€‘compatible LLM endpoint.  
- **MCP integration** â€“ Seamless bridge between LLMs and popular MCP tools (e.g., Kubernetes, Ansible).  
- **Humanâ€‘inâ€‘theâ€‘loop feedback** â€“ Pause for confirmation or iterative refinement at key steps.  
- **Pure Python & GUIâ€‘free** â€“ Fully Pythonâ€‘powered: no frontend skills required for reuse or extension.

### ğŸ“– Quick Start

#### Requirements

- PythonÂ 3.8+  
- OpenAIâ€‘compatible LLM API URL & Key

#### Installation

```bash
pip install aiopstack
```

#### Usage Examples
```bash
# QuickStart, the project will be listening at 0.0.0.0:8051
aiops
```

## ğŸ¤ Contributing

We welcome contributions! If you have suggestions or feature requests, feel free to open an issue or submit a pull request.

### Development Setup

1. Clone the repository:

```bash
git clone https://github.com/ohtaman/streamlit-desktop-app.git
```

2. Install dependencies:

```bash
cd src/aiopstack
pip install -r requirements.txt
```

3. Run Streamlit
```bash
streamlit run app.py
```


