{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def get_parent_topk(self, query: str, query_id: int, topk: int = 100) -> Union[Dict[int, float], List[int]]:\n",
    "        if self.parent_pred_path and osp.exists(self.parent_pred_path):\n",
    "            csv = pd.read_csv(self.parent_pred_path)\n",
    "            csv = csv[['query_id', 'pred_rank']]\n",
    "            csv = csv[csv['query_id'] == query_id]\n",
    "            if len(csv):\n",
    "                pred_rank = eval(csv['pred_rank'].iloc[0])\n",
    "                initial_score_dict = {node_id: 1. / (rank + 1) for rank, node_id in enumerate(pred_rank)}\n",
    "                return initial_score_dict, pred_rank[:topk]\n",
    "\n",
    "        initial_score_dict = self.parent_vss(query, query_id)\n",
    "        node_ids = list(initial_score_dict.keys())\n",
    "        node_scores = list(initial_score_dict.values())\n",
    "        top_k_idx = torch.topk(torch.FloatTensor(node_scores),\n",
    "                               min(topk, len(node_scores)),\n",
    "                               dim=-1).indices.view(-1).tolist()\n",
    "\n",
    "        vss_top_candidates = [node_ids[i] for i in top_k_idx]\n",
    "        return initial_score_dict, vss_top_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stark_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /dfs/user/shirwu/.cache/huggingface/hub/datasets--snap-stanford--stark/snapshots/88269e23e90587f99476c5dd74e235a0877e69be/skb/prime/processed!\n",
      "Loading query embeddings from /dfs/project/kgrlm/multiagent_reward/emb/prime/text-embedding-ada-002/query/query_emb_dict.pt\n",
      "Loaded candidate_emb_dict from /dfs/project/kgrlm/multiagent_reward/emb/prime/text-embedding-ada-002/doc/candidate_emb_dict.pt!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14796, 15307, 20645, 14986, 15365]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import os.path as osp\n",
    "from stark_qa.models import VSS\n",
    "import torch\n",
    "\n",
    "dataset = \"prime\"\n",
    "emb_model = \"text-embedding-ada-002\"\n",
    "emb_dir = \"/dfs/project/kgrlm/multiagent_reward/emb\"\n",
    "\n",
    "if not osp.exists(emb_dir):\n",
    "    subprocess.run([\"python\", \"functional/emb_download.py\", \"--dataset\", \"prime\", \"--emb_dir\", emb_dir])\n",
    "\n",
    "node_emb_dir = osp.join(emb_dir, dataset, emb_model, \"doc\")\n",
    "query_emb_dir = osp.join(emb_dir, dataset, emb_model, \"query\")\n",
    "skb = stark_qa.load_skb(dataset)\n",
    "vss = VSS(skb, query_emb_dir, node_emb_dir, emb_model=emb_model)\n",
    "\n",
    "def get_vss_topk(query, query_id, k=5):\n",
    "    initial_score_dict = vss(query, query_id)\n",
    "    node_ids = list(initial_score_dict.keys())\n",
    "    node_scores = list(initial_score_dict.values())\n",
    "    top_k_idx = torch.topk(torch.FloatTensor(node_scores),\n",
    "                            min(k, len(node_scores)),\n",
    "                            dim=-1).indices.view(-1).tolist()\n",
    "\n",
    "    vss_top_candidates = [node_ids[i] for i in top_k_idx]\n",
    "    return vss_top_candidates\n",
    "\n",
    "candidate_ids = get_vss_topk(\"\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mrr': 0.20000000298023224}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stark_qa.evaluator import  Evaluator\n",
    "def eval_func(candidate_ids, candidate_scores, answer_ids, metrics=[\"mrr\"]):\n",
    "    candidate_score_dict = {_id: score for _id, score in zip(candidate_ids, candidate_scores)} \n",
    "    evaluator = Evaluator(skb.candidate_ids)\n",
    "    return evaluator(candidate_score_dict, torch.LongTensor(answer_ids), metrics)\n",
    "\n",
    "candidate_ids = [14796, 15307, 20645, 14986, 15365]\n",
    "candidate_scores = [1,2,3,4,5]\n",
    "answer_ids = [14796]\n",
    "eval_func(candidate_ids, candidate_scores, answer_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
